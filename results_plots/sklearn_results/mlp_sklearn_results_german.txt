Best auc_score on train set: 0.724
Best parameter set: {'clf__activation': 'relu', 'clf__alpha': 0.01, 'clf__batch_size': 'auto', 'clf__hidden_layer_sizes': (20, 10, 2), 'clf__learning_rate': 'adaptive', 'clf__learning_rate_init': 0.01, 'clf__momentum': 0.8, 'clf__solver': 'adam', 'preprocessing__categorical__base_encoder': OrdinalEncoder(categories=[['A11', 'A12', 'A13', 'A14'],
                           ['A30', 'A31', 'A32', 'A33', 'A34'],
                           ['A40', 'A41', 'A410', 'A42', 'A43', 'A44', 'A45',
                            'A46', 'A48', 'A49'],
                           ['A61', 'A62', 'A63', 'A64', 'A65'],
                           ['A71', 'A72', 'A73', 'A74', 'A75'],
                           ['A91', 'A92', 'A93', 'A94'],
                           ['A101', 'A102', 'A103'],
                           ['A121', 'A122', 'A123', 'A124'],
                           ['A141', 'A142', 'A143'], ['A151', 'A152', 'A153'],
                           ['A171', 'A172', 'A173', 'A174'], ['A191', 'A192'],
                           ['A201', 'A202']],
               dtype=<class 'numpy.float64'>), 'preprocessing__categorical__encoder': 'passthrough', 'preprocessing__numerical__highVifDropper': HighVIFDropper(threshold=10), 'preprocessing__numerical__scaler': StandardScaler(copy=True, with_mean=True, with_std=True)}
Best scores index: 53
Scores for train set:               precision    recall  f1-score   support

       False       0.79      0.79      0.79       560
        True       0.74      0.74      0.74       448

    accuracy                           0.77      1008
   macro avg       0.77      0.77      0.77      1008
weighted avg       0.77      0.77      0.77      1008
Scores for test set:               precision    recall  f1-score   support

       False       0.79      0.74      0.77       140
        True       0.48      0.55      0.51        60

    accuracy                           0.69       200
   macro avg       0.64      0.65      0.64       200
weighted avg       0.70      0.69      0.69       200

f1 score on test set: 0.512
fbeta_score on test set: 0.542
AUC of test set: 0.646
Accuracy of test set: 0.685
Precision of test set: 0.478
Recall of test set: 0.550
